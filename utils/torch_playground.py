import torch
import numpy as np
import random
import os
import time
from contextlib import contextmanager
import sys
import io
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

import torch
# ... ä¸‹é¢æ˜¯åŸæ¥çš„ä»£ç  ...
# ==========================================
# 1. è®¾å¤‡é€‰æ‹© (Device Selection)
# ==========================================
def get_device():
    """è‡ªåŠ¨é€‰æ‹©è®¾å¤‡ï¼Œä¼˜å…ˆä½¿ç”¨ CUDA"""
    if torch.cuda.is_available():
        device = torch.device('cuda')
        # æ‰“å°æ˜¾å¡ä¿¡æ¯ï¼Œç¡®è®¤æ²¡è·‘åœ¨ CPU ä¸Š
        print(f"âœ… Using GPU: {torch.cuda.get_device_name(0)}")
    else:
        device = torch.device('cpu')
        print("âš ï¸ Using CPU")
    return device

# ==========================================
# 2. Seed å›ºå®š (Reproducibility)
# ==========================================
def setup_seed(seed=277527):
    """ä¸€é”®å›ºå®šæ‰€æœ‰éšæœºç§å­ï¼Œç¡®ä¿å®éªŒå¯å¤ç°"""
    torch.manual_seed(seed)#cpuèŒƒå›´å†…çš„seed
    torch.cuda.manual_seed_all(seed)#gpuèŒƒå›´å†…çš„seed
    np.random.seed(seed)#numpyèŒƒå›´å†…çš„seed
    random.seed(seed)#pythonèŒƒå›´å†…çš„seed
    # ä¸ºäº†ä¿è¯ç»å¯¹ä¸€è‡´æ€§ï¼Œå¯èƒ½ä¼šç‰ºç‰²ä¸€ç‚¹ç‚¹é€Ÿåº¦ï¼ˆå¯é€‰ï¼‰
    torch.backends.cudnn.deterministic = True#ç¡®ä¿æ¯æ¬¡è¿”å›çš„å·ç§¯ç®—æ³•æ˜¯ç¡®å®šçš„
    torch.backends.cudnn.benchmark = False#å…³é—­è‡ªåŠ¨å¯»æ‰¾æœ€ä¼˜å·ç§¯ç®—æ³•
    print(f"ğŸ”’ Random seed set to: {seed}")

# ==========================================
# 3. è®¡æ—¶å™¨ (Timer)
# ==========================================
@contextmanager#è¿™æ˜¯ä¸€ä¸ªè£…é¥°å™¨ï¼Œå°†ä¸€ä¸ªç”Ÿæˆå™¨å‡½æ•°è½¬æ¢ä¸ºä¸Šä¸‹æ–‡ç®¡ç†å™¨
#å†™äº†è¿™ä¸ªä»¥åå¯ä»¥ç”¨withè¯­å¥è°ƒç”¨è¿™ä¸ªå‡½æ•°
def time_block(label="Block"):
    """ä¸Šä¸‹æ–‡ç®¡ç†å™¨è®¡æ—¶å™¨
    ç”¨æ³•:
    with time_block("Matrix Mul"):
        output = a @ b
    """
    start = time.perf_counter()
    try:
        yield#ç”¨yieldç§»äº¤â€œæ§åˆ¶æƒâ€ï¼Œè®©withè¯­å¥å—å†…çš„ä»£ç è¿è¡Œã€‚ç±»ä¼¼äºä¸­æ–­ç‚¹
    finally:
        end = time.perf_counter()
        print(f"â±ï¸  {label} time: {end - start:.6f} sec")
    #try finallyç»“æ„ç¡®ä¿æ— è®ºä»£ç å—å†…æ˜¯å¦æŠ›å‡ºå¼‚å¸¸ï¼Œè®¡æ—¶å™¨éƒ½èƒ½æ­£ç¡®ç»“æŸå¹¶æ‰“å°æ—¶é—´
# ==========================================
# 4. å¸¸ç”¨æ‰“å° (Tensor Inspector)
# ==========================================
def inspect(tensor, name="Tensor"):
    """
    æ‰“å°å¼ é‡çš„å…³é”®ä¿¡æ¯ï¼šshape, dtype, device, grad
    é˜²æ­¢çœ¼èŠ±ç¼­ä¹±ï¼Œåªçœ‹æ ¸å¿ƒå±æ€§
    """
    if not isinstance(tensor, torch.Tensor):
        print(f"âŒ {name} is not a Tensor (Type: {type(tensor)})")
        return

    info = f"ğŸ” {name}: \n" \
           f"   Shape:  {tuple(tensor.shape)}\n" \
           f"   Dtype:  {tensor.dtype}\n" \
           f"   Device: {tensor.device}\n" \
           f"   Grad:   {tensor.requires_grad} (Grad Fn: {tensor.grad_fn is not None})"
    
    # å¦‚æœæ˜¯æ ‡é‡ï¼ˆæ¯”å¦‚ Lossï¼‰ï¼Œæ‰“å°æ•°å€¼
    if tensor.numel() == 1:
        info += f"\n   Value:  {tensor.item():.4f}"
    
    print(info)
    print("-" * 30)

# ==========================================
# åˆå§‹åŒ–é»˜è®¤ç¯å¢ƒ
# ==========================================
DEVICE = get_device()
setup_seed()

if __name__ == "__main__":
    # æµ‹è¯•ä¸€ä¸‹æˆ‘ä»¬çš„å·¥å…·
    print("\n--- Testing Playground ---")
    
    # 1. æµ‹è¯•å¼ é‡å’Œ inspect
    x = torch.randn(3, 4, requires_grad=True, device=DEVICE)
    inspect(x, "Test Tensor x")
    
    # 2. æµ‹è¯•è®¡æ—¶å™¨
    with time_block("Sleep Test"):
        y = x.sum()
        time.sleep(0.1)
    
    inspect(y, "Sum Result y")